---
---

@string{aps = {American Physical Society,}}

@article{my_article,
  title={A Voronoi-Diagram-based method for centerline extraction in 3D industrial line-laser reconstruction using a graph-centrality-based pruning algorithm},
  author={Cheng Chen, Xuesong Mei, Dongxiang Hou, Zhengjie Fan, Wangwang Huang},
  abstract={Three-dimensional (3D) line-laser scanning is a widely used 3D reconstruction technique in the industry. As a key procedure of 3D line-laser scanning, centerline extraction of laser stripes directly determines the accuracy of reconstructed 3D models. Because of the noise inside laser stripes, centerline extraction methods based on the gray distribution may provide biased results. In order to address this problem, a Voronoi-diagram-based method (VM) for centerline extraction, which can extract centerlines accurately under severe noises, is proposed. To solve the emerging problems when the Voronoi diagram is applied to line-laser stripes, a fast pruning algorithm based on the distribution of graph centrality is proposed, and two centerline extension algorithms based on least square fitting are developed. The experiments are performed on synthetic images and a line-laser 3D scanner to evaluate the method’s accuracy, robustness, and efficiency. The VM method is proved to have better accuracy and robustness than the traditional method. Simulation experiments show that the VM can extract centerlines from noisy images with an average accuracy of 0.35 pixels. Also, 3D reconstruction experiments of a Φ20-mm standard sphere demonstrate an average accuracy of 0.0282 mm. With four-thread acceleration, the proposed method can process images with a resolution of 2448 × 2048 pixels in 0.5 s. The accuracy and speed of the proposed method can be adjusted by changing the parameter related to the density of contour points, which makes this method flexible and widely applicable in applications with different requirements.},
  journal={Optik},
  volume={261},
  year={2022},
  month={July},
  doi={https://doi.org/10.1016/j.ijleo.2022.169179},
  url={https://www.sciencedirect.com/science/article/abs/pii/S0030402622005344},
  html={https://www.sciencedirect.com/science/article/abs/pii/S0030402622005344},
  preview={voronoi_preview.gif}
}

@article{my_article,
  title={Effects of Image Augmentation and Dual-layer Transfer Machine Learning Architecture on Tumor Classification},
  author={Cheng Chen ,Christine Chen ,Xuesong Mei ,Chaoyang Chen ,Guoxin Ni ,Stephen Lemos},
  abstract={Breast tumor (BT) is the second most common health problem for women. Traditional diagnosis methods can be very labor-intensive and time-consuming with the risk of making a wrong diagnosis. Computer vision and imaging processing techniques using machine learning (ML) methods are emerging to aide in clinical diagnosis. Some machine learning methods have yielded an accuracy of 85% using a single-layer classifier. In this study Inception-V3, a two-layer classifier of transfer machine learning tool was used for image processing with enhancement technologies and for the classification of breast tumor histopathological types. Results showed that image augmentation with dual-layer transfer machine learning algorithms yielded an accuracy of 95.6% in identification of breast tumor pathologic types, which was higher than previously reported methods in the literature. Different image preprocessing methods, dataset preparing methods, and classifier architectures were also studied to identify the optimal algorithm. Results showed that multiple-layer processing algorithms using color images, instead of black and white images, yielded a better accuracy in histopathological type classification.},
  journal={ICCPR '19: Proceedings of the 2019 8th International Conference on Computing and Pattern Recognition},
  pages={282--287},
  year={2019},
  month={October},
  doi={https://doi.org/10.1145/3373509.3373584},
  url={https://dl.acm.org/doi/10.1145/3373509.3373584},
  html={https://dl.acm.org/doi/10.1145/3373509.3373584},
  preview={tumor_classify.png}
}